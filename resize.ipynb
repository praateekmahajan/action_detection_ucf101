{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "# import skvideo.io\n",
    "from data_loader import DataClass\n",
    "# video = io.open('test.avi', 'r+b').read()\n",
    "FOLDER = \"data/resize\"\n",
    "# cv2.imshow(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {i:0 for i in range(101)}\n",
    "train_counter = {i:0 for i in range(100)}\n",
    "val_counter = {i:0 for i in range(100)}\n",
    "arr = []\n",
    "with open(\"data/all_images1.txt\") as f:\n",
    "    for line in f:\n",
    "        label = int(line.split(\" \")[1])\n",
    "        arr.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.asarray(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[::-1].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([296, 141, 141, 141, 139, 138, 138, 134, 130, 128, 126, 107, 107,\n",
       "       106, 106, 104, 104, 103, 103, 103, 102, 101, 100, 100, 100, 100,\n",
       "       100, 100, 100, 100, 100, 100,  99,  99,  99,  99,  98,  98,  97,\n",
       "        96,  96,  96,  95,  95,  95,  95,  94,  92,  92,  92,  90,  90,\n",
       "        90,  90,  90,  89,  89,  89,  89,  88,  88,  88,  88,  88,  87,\n",
       "        87,  87,  86,  86,  85,  85,  85,  85,  85,  85,  85,  85,  85,\n",
       "        85,  84,  84,  84,  84,  84,  84,  84,  84,  83,  83,  83,  83,\n",
       "        83,  83,  83,  83,  83,  82,  82,  82,  82])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091174400"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 *  296 * 3 * 160 * 240 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DATASET = \"data/\"\n",
    "IMAGE_DATASET = \"UCF101_images/\"\n",
    "\n",
    "dataloader = {'train' : DataClass(FOLDER_DATASET, IMAGE_DATASET, \"train1.txt\"),\n",
    "              'validation' : DataClass(FOLDER_DATASET, IMAGE_DATASET, \"val1.txt\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = dataloader['train'].getbatch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.from_numpy(input).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNGRU, self).__init__()\n",
    "        self.input_dim = 1000\n",
    "        self.hidden_layers = 101\n",
    "        self.rnn_layers = 2\n",
    "#         self.classes = 101\n",
    "#         self.sample_rate = 12\n",
    "        \n",
    "        self.conv = torchvision.models.resnet18(pretrained=True)\n",
    "        for param in self.conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_layers, self.rnn_layers)\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_layers, self.rnn_layers, dropout=0.2)\n",
    "#         self.linear = nn.Linear(\n",
    "#             in_features=self.hidden_layers, out_features=self.classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, t,c, w, h = x.size(0), x.size(1), x.size(2), x.size(3), x.size(4)\n",
    "        x = x.view(t*n,c,w,h)\n",
    "        conv_output = self.conv(x) #convolve allframes       \n",
    "        conv_output = conv_output.view(n,t,-1).transpose(1,0)\n",
    "#         conv_output = self.conv(x).view(x.size(0),x.size(1),-1).transpose(1,0)\n",
    "        out, _ = self.gru(conv_output) # pass convolution to gru\n",
    "        lstm_output = out[-1, :, :].data\n",
    "#         print(lstm_output.size())\n",
    "#         output = self.linear(lstm_output) #linear layer \n",
    "        return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "model_ft = CNNGRU()\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "# print(model_ft)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Remove all parameters not to be optimized\n",
    "ignored_params = list(map(id, model_ft.conv.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model_ft.parameters())\n",
    "                     \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD([{'params': base_params}], lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924049"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model_ft.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403633952"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12613561 * 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3L"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = input.size()\n",
    "size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 13.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "def func():\n",
    "    input, label = dataloader['train'].getbatch(3)\n",
    "    input = Variable(torch.from_numpy(input).float())\n",
    "    model_ft(input)\n",
    "%timeit func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-114e86a5df51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m267\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_r_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"data/all_images1.txt\") as f:\n",
    "    for line in f:\n",
    "        image_folder = line.split(\" \")[0]\n",
    "        length = line.split(\" \")[1]\n",
    "        image_url =  \"data/\" + \"UCF101_images/\" + image_folder\n",
    "        image_resize_url =  \"data/\" + \"UCF101_images_r/\" + image_folder\n",
    "        \n",
    "        \n",
    "        for i in range(0, int(length)): #pad the beginning\n",
    "            image = cv2.imread(image_url + \"_\" + str(i) + \".jpg\")                \n",
    "            image = cv2.resize(image, (267,200), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imwrite(image_url + \"_r_\" + str(i) + \".jpg\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

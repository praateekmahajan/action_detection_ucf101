{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import skvideo.io\n",
    "from data_loader import DataClass\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "use_gpu = True and torch.cuda.is_available()\n",
    "FOLDER_DATASET = \"data/\"\n",
    "IMAGE_DATASET = \"UCF101_images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {'train' : DataClass(FOLDER_DATASET, IMAGE_DATASET, \"train1.txt\"),\n",
    "              'validation' : DataClass(FOLDER_DATASET, IMAGE_DATASET, \"val1.txt\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNGRU, self).__init__()\n",
    "        self.input_dim = 1000\n",
    "        self.hidden_layers = 101\n",
    "        self.rnn_layers = 1\n",
    "#         self.classes = 101\n",
    "#         self.sample_rate = 12\n",
    "        \n",
    "        self.conv = torchvision.models.resnet18(pretrained=True)\n",
    "        for param in self.conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_layers, self.rnn_layers)\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_layers, self.rnn_layers)\n",
    "#         self.linear = nn.Linear(\n",
    "#             in_features=self.hidden_layers, out_features=self.classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, t = x.size(0), x.size(1)\n",
    "        x = x.view(t*n,x.size(2),x.size(3),x.size(4))\n",
    "        conv_output = self.conv(x) #convolve allframes       \n",
    "        conv_output = conv_output.view(n,t,-1).transpose(1,0)\n",
    "        out, _ = self.gru(conv_output) # pass convolution to gru\n",
    "        lstm_output = out[-1, :, :]\n",
    "#         print(lstm_output.size())\n",
    "#         output = self.linear(lstm_output) #linear layer \n",
    "        return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = CNNGRU()\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "# print(model_ft)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Remove all parameters not to be optimized\n",
    "ignored_params = list(map(id, model_ft.conv.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model_ft.parameters())\n",
    "                     \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD([{'params': base_params}], lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.8604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Time taken 6.37043499947\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "input, labels = dataloader['train'].getbatch(2)\n",
    "input = Variable(torch.from_numpy(input)).float()\n",
    "labels = Variable(torch.from_numpy(labels))\n",
    "output = model_ft(input)\n",
    "loss = criterion(output, labels)\n",
    "print(loss)\n",
    "print (\"Time taken\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3.9476\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Time taken 43.8233220577\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.arange(12)\n",
    "# a[0:6] = 0\n",
    "# a[6:] = 1\n",
    "a = np.asarray([['a1','a2','a3','a5','a5','a6'],['b1','b2','b3','b4','b5','b6']])\n",
    "print(a)\n",
    "print(a.reshape(-1))\n",
    "b = a.reshape(2,6)\n",
    "print(b)\n",
    "print(\"\\n\\n\\n\")\n",
    "# print(a.reshape(6,2))\n",
    "print(b.transpose(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloader, batch_size, use_gpu, num_epochs=25):\n",
    "    since = time.time()\n",
    "    dataset_sizes = {x: len(dataloader[x]) for x in ['train', 'validation']}\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i in range(int(dataset_sizes[phase]/batch_size)):\n",
    "                # get the inputs\n",
    "                inputs, labels = dataloader[phase].getbatch(batch_size)\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(torch.from_numpy(inputs).float().cuda())\n",
    "                    labels = Variable(torch.from_numpy(labels).cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(torch.from_numpy(inputs).float()), Variable(torch.from_numpy(labels))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "#                 print(outputs.view(-1), labels.view(1))\n",
    "                loss = criterion(outputs, labels)\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dataloader, 2, use_gpu, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10, 3, 15, 15)\n",
      "(2, 5, 3, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((2,10,3,15,15))\n",
    "b = np.zeros((2,5,3,15,15))\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "print(np.repeat(b, [1], axis=1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

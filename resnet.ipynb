{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import skvideo.io\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "use_gpu = True and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "FOLDER_DATASET = \"data/\"\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "transforms.RandomCrop(224),\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class FrameData(Dataset):\n",
    "\n",
    "    def __init__(self, FOLDER_DATASET, file_name, timestep = 12,transform=None):\n",
    "        self.__xs = []\n",
    "        self.__ys = []\n",
    "        self.transform = transform\n",
    "        self.timestep = timestep\n",
    "        # counter = 0\n",
    "        with open(FOLDER_DATASET + file_name) as f:\n",
    "            for line in f:\n",
    "                # counter += 1\n",
    "#                 print(line.split(\" \")[0].split(\"/\")[1])\n",
    "#                 print(np.float32(line.split()[1]) - 1)\n",
    "#                 break\n",
    "            \n",
    "                self.__xs.append(FOLDER_DATASET + \"UCF101/\" + line.split(\" \")[0])\n",
    "                self.__ys.append(np.float32(line.split(\" \")[1]))\n",
    "#             print(counter)\n",
    "\n",
    "    # Override to give PyTorch access to any image on the dataset\n",
    "    def __getitem__(self, index):\n",
    "        vid = skvideo.io.vread(self.__xs[index])\n",
    "        frames, width, height, channels = vid.shape\n",
    "        time_steps = int(frames/self.timestep) #sample rate is number of frames to extract per second \n",
    "        vid = torch.from_numpy(vid[::self.timestep].transpose(0,3,1,2)).float()\n",
    "        label = torch.from_numpy(np.asarray(self.__ys[index]).reshape([1])).long()\n",
    "        return vid, label\n",
    "\n",
    "    # Override to give PyTorch size of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.__xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = {x : FrameData(FOLDER_DATASET, x + \"1.txt\") for x in ['train', 'validation']}                  \n",
    "# data_loader = {'train' : DataLoader(data_set['train'], batch_size=1, shuffle=True, num_workers=1),\n",
    "#                'validation' : DataLoader(data_set[x], batch_size=1, shuffle=False, num_workers=1),\n",
    "#               }\n",
    "# for x in ['train','validation']:\n",
    "#     for data in data_loader[x]:\n",
    "#         frames, label = data\n",
    "#         print(type(frames))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_bceloss(data, optimizer, model, criterion,batch_size=1):\n",
    "    model.train()\n",
    "    input1, input2, labels = data\n",
    "    if batch_size == 1:\n",
    "        input1._squeeze()\n",
    "        input2._squeeze()\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        input1, input2, labels = Variable(input1.cuda()), Variable(input2.cuda()), Variable(\n",
    "            labels.view(-1).cuda())\n",
    "    else:\n",
    "        input1, input2, labels = Variable(input1), Variable(input2), Variable(labels.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input1, input2)\n",
    "    loss = criterion(outputs.view(-1), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNGRU, self).__init__()\n",
    "        self.input_dim = 1000\n",
    "        self.hidden_layers = 200\n",
    "        self.rnn_layers = 2\n",
    "        self.classes = 101\n",
    "        self.sample_rate = 12\n",
    "        \n",
    "        self.conv = torchvision.models.resnet18(pretrained=True)\n",
    "        for param in self.conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_layers, self.rnn_layers)\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_layers, self.rnn_layers)\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.hidden_layers, out_features=self.classes)\n",
    "\n",
    "    def forward(self, video):\n",
    "        conv_output = self.conv(video) #convolve allframes \n",
    "        conv_output = torch.unsqueeze(conv_output,1)        \n",
    "\n",
    "        out, _ = self.gru(conv_output) # pass convolution to gru\n",
    "        lstm_output = out[-1, :, :]\n",
    "        output = self.linear(lstm_output) #linear layer \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, data_set, use_gpu, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    data_loader = {'train' : DataLoader(data_set['train'], batch_size=1, shuffle=True, num_workers=1),\n",
    "               'validation' : DataLoader(data_set['validation'], batch_size=1, shuffle=False, num_workers=1),\n",
    "              }\n",
    "    dataset_sizes = {x: len(data_set[x]) for x in ['train', 'validation']}\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in data_loader[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.squeeze()\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "#                 print(outputs.view(-1), labels.view(1))\n",
    "                loss = criterion(outputs, labels.view(1))\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = CNNGRU()\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "# print(model_ft)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Remove all parameters not to be optimized\n",
    "ignored_params = list(map(id, model_ft.conv.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model_ft.parameters())\n",
    "                     \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD([{'params': base_params}], lr=0.001, momentum=0.9)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, data_set, use_gpu, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_params = list(map(id, model_ft.conv.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model_ft.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([\n",
    "            {'params': base_params},\n",
    "            {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "        ], lr=opt.lr*0.1, momentum=0.9)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
